---
layout:     post
title:      Pytorch 笔记
subtitle:  时刻进步
date:       2023-6-17
catalog: true
tags: [Python]

---

# PyTorch 笔记

> 学习过程中遇到的问题和解决方案

## 如何使用本地数据集

以`Cifar`数据集为例

- 先去官网下载好数据集

- 将数据集解压放到项目的`data`目录下（或者其他目录也行）

- 使用`torchvison`自带的`datasets`库来导入数据

  **不要更改解压后的目录名称，不然 datasets 库会找不到！**

  ```python
  import os
  from torch import nn
  import torch
  from torchvision import datasets, transforms
  import ConvAutoencoder
  #数据预处理
  transform = transforms.Compose([
      transforms.ToTensor()
  ])
  current_dir = os.getcwd()  # 获取当前工作目录
  parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))  # 获取当前工作目录的上一级目录
  data_path=os.path.join(parent_dir+"\data")
  
  train_data=datasets.CIFAR10(root=data_path,train=True,transform=transform,download=False)
  train_loader=torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True, num_workers=2)
  ```

## 如何查看`DataLoader`中的数据形状

- 将对应的 loader 转换为迭代器，然后使用`next()`函数来从中取出一个数据

  ```python
  train_iter=iter(train_loader)
  image,label = next(train_iter)
  ```

- 接下来就可以查看数据形状了，直接`Jupyter notebook`中输出就完事了

  ```python
  image.shape
  ```

## 为什么 PyTorch 中，模型初始化的`super()`方法要带上模型自身的名称

例如：

```python
class CAE_decoder(nn.Module):  
    def __init__(self):
        super(CAE_decoder,self).__init__()
        self.conv1=nn.ConvTranspose2d(4,8,kernel_size=3,stride=1,padding=1)
        self.conv2=nn.ConvTranspose2d(8,16,kernel_size=3,stride=2,padding=1)
        self.conv3=nn.ConvTranspose2d(16,3,kernel_size=3,stride=2,padding=1)
        self.relu=nn.ReLU()

    def forward(self,x):  #x: [b,4,20,20]  -> [b,8,40,40]
        x=self.relu(self.conv1(x))  #[b,8,40,40]->[b,16,20,20
        x=self.relu(self.conv2(x))  #[b,16,20,20]->[b,8,10,10
        x=self.conv3(x)  #[b,8,10,10]->[b,3,5,
        return x
```

为什么要在 `super()` 中带上类自身的名称 `CAE_decoder` 呢？

这是因为在多重继承的情况下，一个类可能同时继承自多个父类，因此需要指定具体要调用的父类。在单一继承的情况下，指定类自身的名称并不是必需的，可以简化为 `super().__init__()`。

但是为了保持代码的清晰和明确，推荐在 `super()` 中明确指定类自身的名称，以便在代码中明确指定调用的父类方法。

总结起来，`super(CAE_decoder, self).__init__()` 的作用是调用 `CAE_decoder` 类的父类 `nn.Module` 的初始化方法，以初始化 `CAE_decoder` 类的对象。

## 为什么 PyTorch 中数组里面放向量可以获得索引值

在学习D2L的时候看到这样一段代码

```python
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    # 这些样本是随机读取的，没有特定的顺序
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]
```

很不理解其中的`features[batch_indices]`语句，然后在 Python 里面试了一下，写了以下代码

```python
a={"Google","Alibaba","Baidu","Tencent"}
c=list(a)
d=list(range(0,2))
print(c[d])
```

我就很奇怪，一直报错

```bash
TypeError: list indices must be integers or slices, not list
```

但是在第一段代码里面就是可以啊，最终查找资料发现，**在一个数组里面放一个列表，获得对应索引值所指向的元素，是`torch`中`tensor`的特性，在 Python 的`list`中不可以这么用**

## 在多次运行 Python 脚本时如何防止内存累计

Python 解释器在 Windows平台 执行创建多进程的程序时，子进程会读取当前 Python 文件，用以创建进程，在子进程读取当前文件时，读取到创建子进程的代码时又会创建新的子进程，这样程序就陷入递归创建进程的状态

由于 Python 解释器中对于创建子进程有一个最大数量限制来保护我们的计算机，防止其内存溢出，因此程序会抛出异常

```bash
RuntimeError:
An attempt has been made to start a new process before the
current process has finished its bootstrapping phase.
This probably means that you are not using fork to start your
child processes and you have forgotten to use the proper idiom
in the main module:
　　if name == ‘main‘:
　　　　freeze_support()
　　　　…
The “freeze_support()” line can be omitted if the program
is not going to be frozen to produce an executable.
```

这样的话我们就需要在脚本中使用以下方式来建立程序入口

```python
if __name__ == '__main__':
    main()
```

但这样又会产生一个问题，在当前脚本执行结束后，该脚本的进程并不会自动终止，而是会一直运行，这样下去，会占用越来越多的系统的内存

解决方式，加上一行代码，在脚本执行完毕后自动终止当前 Python 解释器

```python
if __name__ == '__main__':
    main()
    sys.exit()
```

## 如何对网络中每一层的权重进行初始化操作

如果我们将继承自`nn.Module`的网络直接传入`for...in... `语句，第一个元素会是网络自身，因此，初始化的示例函数如下：

```python
def init_weight(net):
    for layers in net.modules():
        if(type(layers) == nn.Conv2d or type(layers) == nn.Linear):
            nn.init.xavier_uniform_(layers.weight)
```

## 图像分块处理

```python
y_slices = y.chunk(self.num_slices, 1)
```

这行代码的作用是将张量y在通道维度(dimension 1)上分块,分成self.num_slices个切片。

具体来看:

1. self.num_slices是一个模型初始化时定义的切片数量,例如可以取10。
2. 输入张量y的shape假设为[N, 320, 16, 16],有320个通道。
3. **chunk操作**将其在第1维(通道维度)等距切分成10块,每块包含32(320/10)个通道。
4. cutting的结果是y_slices是一个包含10个tensor的list,每个tensor的shape为[N, 32, 16, 16]。
5. 这样就将y的不同通道切分成了多个特征切片(feature slices)。
6. 后续模型会在每个切片上分别进行压缩编码、熵编码等操作。
7. 将一个高维张量分块处理,是降低模型Computation和Memory复杂度的常用技巧。

所以这行代码使用了chunk操作实现了按通道切分特征图的功能,使图像可以分块进行压缩处理,降低了模型复杂度。

# 常见错误

## 在网络定义中，对最后一层应用了激活函数

实际上不行

## 激活函数未定义就直接使用了

例如：

```python
nn.ReLU(self.conv1(x)) 
```

实际上这是错的，上面这行进行的是类的初始化操作，传入一个 Tensor 肯定就错了

应该这样：

```python
class CAE_decoder(nn.Module):  
    def __init__(self):
        super(CAE_decoder,self).__init__()
        self.conv1=nn.ConvTranspose2d(4,8,kernel_size=3,stride=1,padding=1)
        self.conv2=nn.ConvTranspose2d(8,16,kernel_size=3,stride=2,padding=1)
        self.conv3=nn.ConvTranspose2d(16,3,kernel_size=3,stride=2,padding=1)
        self.relu=nn.ReLU()

    def forward(self,x):  #x: [b,4,20,20]  -> [b,8,40,40]
        x=self.relu(self.conv1(x))  #[b,8,40,40]->[b,16,20,20
        x=self.relu(self.conv2(x))  #[b,16,20,20]->[b,8,10,10
        x=self.conv3(x)  #[b,8,10,10]->[b,3,5,
        return x
```

